argparse_cfg:
  gpus:
    bind_to: processor_cfg.gpus
    help: number of gpus
  batch_size:
    bind_to: processor_cfg.batch_size
  checkpoint:
    bind_to: processor_cfg.checkpoint
    help: the checkpoint file to load from
  video_dir:
    bind_to: processor_cfg.video_dir
    help: folder for videos

processor_cfg:
  type: "processor.recognition_granary.realtime_detect"
  workers: 16
  checkpoint: ./work_dir/recognition/st_gcn/dataset_granary/latest.pth
  tracker_cfg: null
  video_dir: data/action/video
  category_annotation: resource/category_annotation_granary.json

  detection_cfg:
    model_cfg: configs/mmdet/cascade_rcnn_r50_fpn_1x.py
    checkpoint_file: mmskeleton://mmdet/cascade_rcnn_r50_fpn_20e
    bbox_thre: 0.8
  estimation_cfg:
    model_cfg: configs/pose_estimation/hrnet/pose_hrnet_w32_256x192_test.yaml
    checkpoint_file: mmskeleton://pose_estimation/pose_hrnet_w32_256x192
    data_cfg:
      image_size:
        - 192
        - 256
      pixel_std: 200
      image_mean:
        - 0.485
        - 0.456
        - 0.406
      image_std:
        - 0.229
        - 0.224
        - 0.225
      post_process: true

  # model setting
  model_cfg:
    type: "models.backbones.ST_GCN_18"
    in_channels: 3
    num_class: 3
    edge_importance_weighting: True
    graph_cfg:
      layout: "coco"
      strategy: "spatial"

  # dataset setting
  dataset_cfg:
    type: "datasets.DataPipeline"
    data_source:
      type: "datasets.SkeletonLoader"
      data_dir: ./data/action/annotation
      num_track: 2
      num_keypoints: 17
    pipeline:
      - { type: "datasets.skeleton.normalize_by_resolution" }
      - { type: "datasets.skeleton.mask_by_visibility" }
      - { type: "datasets.skeleton.pad_zero", size: 300 }
      - { type: "datasets.skeleton.random_crop", size: 300 }
      - { type: "datasets.skeleton.transpose", order: [0, 2, 1, 3] }
      - { type: "datasets.skeleton.to_tuple" }
  # dataloader setting
  batch_size: 3
  gpus: 1

